{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeworks-data/mvp-dpe/blob/main/notebooks/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN_zoRKylVYQ"
      },
      "source": [
        "# Project Scoping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mpyvJK66X81"
      },
      "source": [
        "## Description \n",
        "\n",
        "The following notebook details our approach to building a modeling pipeline, and saving runs to MLflow, to predict energy consumption for a given space in France (apartment, building, mall...)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Az4EeYH43YO"
      },
      "source": [
        "# In order to get the execution time of each cell\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "!pip install mlflow --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!pip install scikit-optimize\n",
        "!pip install bayesian-optimization\n",
        "!pip install catboost\n",
        "!pip install category_encoders\n",
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ4iXd6q7svH"
      },
      "source": [
        "* We only ignore the warnings for format concerns. However, they were taken into consideration and only ignored after previous execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47TYYNHameGs",
        "outputId": "1368d20c-c27a-48fe-973c-1b0ccdf3626c"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.51 ms (started: 2021-06-09 07:02:12 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1jLx1m0J0Xf"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1mIJWpYHAjl"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMQ6c3zNJ7J1",
        "outputId": "52eb5a1b-822e-4938-8670-e325343457d1"
      },
      "source": [
        "# For data manipulation and data viz\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import matplotlib.pyplot as plt \n",
        "import missingno as msno\n",
        "import category_encoders as ce\n",
        "\n",
        "# Scikit-Learn Functions\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score \n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Models\n",
        "import lightgbm as lgb\n",
        "import catboost as cgb\n",
        "\n",
        "# MLflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Optimization functions\n",
        "from bayes_opt import BayesianOptimization\n",
        "from skopt import gp_minimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.plots import plot_convergence\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
        "\n",
        "# Utils\n",
        "from pyngrok import ngrok\n",
        "import shutil\n",
        "import logging"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.69 s (started: 2021-06-09 07:02:12 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HCIrHdMJnNT"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAuXIJ5OboaK"
      },
      "source": [
        "* Let's mount data from Google Drive :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1kOF-wXvEeg",
        "outputId": "55ab5cbd-9064-4950-fb61-930ebc259bae"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "time: 2min 24s (started: 2021-06-09 07:02:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XSoYmqrVUfF"
      },
      "source": [
        "* Let's load the data and merge the clean df with the temperature data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wepjiMigJs_0"
      },
      "source": [
        "dataset_clean = pd.read_csv('/content/drive/My Drive/MVP/DPE/datasets/dpe_clean.csv', decimal='.', low_memory=False)\n",
        "temp = pd.read_csv('/content/drive/My Drive/MVP/DPE/datasets/temperatures.csv')\n",
        "# Merge dpe data with temperature data\n",
        "data = pd.merge(dataset_clean, temp, on ='code_departement')\n",
        "data.to_csv('/content/drive/My Drive/MVP/DPE/datasets/dpe_enriched.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG-q6iLnJWJv"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3HuL3C4DM4M",
        "outputId": "3fb9967c-836c-4b27-98ad-c6f713966e28"
      },
      "source": [
        "class Parameters:\n",
        "    def __init__(self):\n",
        "    # Preprocessing parameters\n",
        "        self.data_name = \"DPE\"\n",
        "        self.data_path = \"/content/drive/My Drive/MVP/DPE/datasets/dpe_enriched.csv\"\n",
        "        self.img_path = \"/content/drive/My Drive/MVP/DPE/images\"\n",
        "        self.model_path = \"/content/drive/My Drive/MVP/DPE/models\"\n",
        "        self.k_folds = 10 \n",
        "        self.test_size = 0.25\n",
        "        self.random_state = 42\n",
        "\n",
        "DEFAULT_PARAMETERS = Parameters()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.82 ms (started: 2021-06-09 07:04:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu0drALdz-CB",
        "outputId": "4213fe4b-4887-4b98-bc54-8dd7b57ed5b4"
      },
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO \n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.23 ms (started: 2021-06-09 07:04:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqqrTUFX0xQi"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1kVl2L_W-9v",
        "outputId": "d4bd6982-317e-486a-a6bc-7fe0bd951366"
      },
      "source": [
        "class Pipeline:\n",
        "    \"\"\"\n",
        "    Class that builds ML validation pipeline based on trained model and logs it in MLflow.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        \"\"\"\n",
        "        Init pipeline with datasets, trained model and performance metrics. \n",
        "        \"\"\"\n",
        "        self.params = model.params\n",
        "        self.dataset = None\n",
        "        self.model_name = model.model_name\n",
        "\n",
        "        self.model = model.model # Instance of Model class\n",
        "        self.X_train = model.X_train\n",
        "        self.y_train = model.y_train\n",
        "        self.X_test = model.X_test\n",
        "        self.y_test = model.y_test\n",
        "        self.y_test_class = None\n",
        "        self.y_pred = model.y_pred # Consommation energie\n",
        "        self.y_pred_class = None # Classe consommation energie\n",
        "\n",
        "        self.classes = ['A','B','C','D','E','F','G']\n",
        "        self.confusion_matrix = None\n",
        "        self.classification_metrics = None\n",
        "\n",
        "        self.logger = logging.getLogger('Pipeline')\n",
        "\n",
        "        self.run()\n",
        "\n",
        "    \n",
        "    def k_fold_cross_validation(self):\n",
        "        \"\"\"\n",
        "        Apply k-fold cross validation.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting K-fold validation...')\n",
        "\n",
        "        kfold_scores = cross_val_score(self.model, self.X_train, self.y_train, cv=self.params.k_folds)\n",
        "\n",
        "        # Log accuracy metrics to MLflow \n",
        "        mlflow.log_metric(f\"average_accuracy\", kfold_scores.mean())\n",
        "        mlflow.log_metric(f\"std_accuracy\", kfold_scores.std())\n",
        "       \n",
        "        self.logger.info('K-fold validation finished !!!')\n",
        "\n",
        "    \n",
        "    def model_evaluation(self):\n",
        "        \"\"\"\n",
        "        Evaluate model using classification metrics by converting energy consumption (regression) to classes.\n",
        "        And log metrics to MLflow.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting model evaluation...')\n",
        "        # Assign classes to test target\n",
        "        c = self.y_test.copy() \n",
        "        conditions = [(c <= 50), (c > 50) & (c <= 90), (c> 90) & (c <= 150),(c > 150) & (c <= 230), (c > 230) & (c <= 330), (c > 330) & (c <450), (c >= 450)]\n",
        "        self.y_test_class = np.select(conditions,self.classes)\n",
        "\n",
        "        # Assign classes to predicted target\n",
        "        c = self.y_pred.copy()\n",
        "        conditions = [(c <= 50), (c > 50) & (c <= 90), (c> 90) & (c <= 150),(c > 150) & (c <= 230), (c > 230) & (c <= 330), (c > 330) & (c <450), (c >= 450)]\n",
        "        self.y_pred_class = np.select(conditions,self.classes)\n",
        "\n",
        "        # Compute classification report\n",
        "        self.classification_metrics = metrics.classification_report(self.y_test_class, self.y_pred_class)\n",
        "        self.confusion_matrix = metrics.confusion_matrix(self.y_test_class, self.y_pred_class)\n",
        "\n",
        "        # Log accuracy to MLflow\n",
        "        mlflow.log_metric(f\"train_accuracy\", self.model.score(self.X_train, self.y_train))\n",
        "        mlflow.log_metric(f\"test_accuracy\", self.model.score(self.X_test, self.y_test))\n",
        "\n",
        "        self.logger.info('Model evaluation finished!!!')\n",
        "\n",
        "\n",
        "    def log_confusion_metrics(self):\n",
        "        \"\"\"\n",
        "        Log classification report metrics to MLflow.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting logging confusion matrix...')\n",
        "\n",
        "        classification_array = self.classification_metrics.split()\n",
        "\n",
        "        i = 5\n",
        "        for classe in self.classes:\n",
        "            precision = float(classification_array[i])\n",
        "            mlflow.log_metric(f\"precision_{classe}\", precision)\n",
        "\n",
        "            recall = float(classification_array[i+1])\n",
        "            mlflow.log_metric(f\"recall_{classe}\", recall)\n",
        "\n",
        "            f1_score = float(classification_array[i+2])\n",
        "            mlflow.log_metric(f\"f1-score_{classe}\", f1_score)\n",
        "\n",
        "            support = float(classification_array[i+3])\n",
        "            mlflow.log_metric(f\"support_{classe}\", support)\n",
        "\n",
        "            i = i+5\n",
        "\n",
        "        accuracy = float(classification_array[i])\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        self.logger.info('Logging confusion matrix finished!!!')\n",
        "\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Save model and performance plots.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting saving model...')\n",
        "        # Track confusion matrix plot\n",
        "        fig, axes = plt.subplots(figsize=(10,10))\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=self.confusion_matrix, display_labels=self.classes)\n",
        "        disp = disp.plot(ax=axes)\n",
        "        plt.savefig(f\"{self.params.img_path}/confusion_matrix_{self.model_name}.png\")\n",
        "        # Log plot\n",
        "        mlflow.log_artifact(f\"{self.params.img_path}/confusion_matrix_{self.model_name}.png\")\n",
        "\n",
        "        # Feature Importance\n",
        "        explainer = shap.TreeExplainer(self.model)\n",
        "        shap_values = explainer.shap_values(self.X_test)\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=(10,10))\n",
        "        shap.summary_plot(shap_values, self.X_test, show=False)\n",
        "        plt.savefig(f\"{self.params.img_path}/feature_importance_{self.model_name}.png\", dpi=150, bbox_inches='tight')\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=(10,10))\n",
        "        shap.summary_plot(shap_values, self.X_test, plot_type='bar', show=False)\n",
        "        plt.savefig(f\"{self.params.img_path}/feature_importance_bar_{self.model_name}.png\", dpi=150, bbox_inches='tight')\n",
        "\n",
        "        # Log the best model\n",
        "        mlflow.sklearn.save_model(self.model, f\"{self.params.model_path}/_{self.model_name}\", serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_PICKLE)\n",
        "        \n",
        "        self.logger.info('Saving model finished!!!')\n",
        "    \n",
        "    \n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run class methods in order.\n",
        "        \"\"\"\n",
        "        self.logger.info('Running Pipeline...')\n",
        "        self.k_fold_cross_validation()\n",
        "        self.model_evaluation()\n",
        "        self.log_confusion_metrics()\n",
        "        self.save_model()\n",
        "        self.logger.info('TaDaaaa! Pipeline finished!!!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 227 ms (started: 2021-06-09 07:04:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E3ggGTkfqDH",
        "outputId": "6891eec1-db41-4334-f09d-663262d7c229"
      },
      "source": [
        "class Model:\n",
        "    \"\"\"\n",
        "    Class that defines preprocessing, training and hyperparameter tuning methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params):\n",
        "        \"\"\"\n",
        "        Init class with data set splits.\n",
        "        \"\"\"\n",
        "        self.dataset = None\n",
        "        self.params = params\n",
        "\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.y_pred = None\n",
        "        self.model = None\n",
        "\n",
        "        self.logger = logging.getLogger('Model')\n",
        "\n",
        "\n",
        "    def load_dataset(self):\n",
        "        \"\"\"\n",
        "        Load dataset into a pandas dataframe.\n",
        "        \"\"\"\n",
        "        self.logger.info('Loading dataset...')\n",
        "        self.dataset = pd.read_csv(self.params.data_path, decimal='.', low_memory=False, index_col=0)\n",
        "        self.logger.info('Dataset loaded!!!')\n",
        "\n",
        "\n",
        "    def preprocessing(self):\n",
        "        \"\"\"\n",
        "        Preprocessing dataset, includes \n",
        "        dropping useless features and selecting the target.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting preprocessing...')\n",
        "        self.X = self.dataset.drop(['consommation_energie','estimation_ges', 'classe_consommation_ges',\n",
        "                            'date_visite_diagnostiqueur', 'date_etablissement_dpe','energie_totale',\n",
        "                            'code_region','code_insee_commune_actualise',\n",
        "                            'annee_construction','classe_estimation_ges','annee_visite'],axis = 1)\n",
        "\n",
        "        self.y = self.dataset['consommation_energie']\n",
        "        self.logger.info('Preprocessing finished!!!')\n",
        "\n",
        "\n",
        "    def train_test_split(self):\n",
        "        \"\"\"\n",
        "        Split data into train and test sets.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting train-test split...')\n",
        "        # Use stratify to make sure we get an equal distribution of energy classes over the data sets\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X,self.y, test_size=self.params.test_size, \n",
        "                                                                                random_state=self.params.random_state, \n",
        "                                                                                stratify=self.X['classe_consommation_energie'])\n",
        "\n",
        "        self.X_train = self.X_train.drop(['classe_consommation_energie'], axis = 1)\n",
        "        self.X_test = self.X_test.drop(['classe_consommation_energie'], axis = 1)\n",
        "        self.logger.info('Train-test split finished!!!')\n",
        "\n",
        "        \n",
        "    def parameter_tuning(self):\n",
        "        \"\"\"\n",
        "        Hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        self.logger.error(\"Hyperparameter tuning fail!!!\")\n",
        "        raise Exception (\"Hyperparameter tuning!!!\")\n",
        "       \n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        Train model with best parameters.\n",
        "        \"\"\"\n",
        "        self.logger.error(\"Training failed!!!\")\n",
        "        raise Exception (\"Training fail!!!\")\n",
        "        \n",
        "\n",
        "    def predict_target(self):\n",
        "        \"\"\"\n",
        "        Predict target values.\n",
        "        \"\"\"\n",
        "        self.logger.info('Predicting...')\n",
        "        self.y_pred = self.model.predict(self.X_test)\n",
        "        self.logger.info('Modeling finished!!!')\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\" \n",
        "        Run class methods in order.\n",
        "        \"\"\"\n",
        "        self.logger.info('Running Model...')\n",
        "        self.load_dataset()\n",
        "        self.preprocessing()\n",
        "        self.train_test_split()\n",
        "        self.parameter_tuning()\n",
        "        self.train_model()\n",
        "        self.predict_target()\n",
        "        self.logger.info('Modeling finished!!!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 67.2 ms (started: 2021-06-09 07:04:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHqed0zDCCIm"
      },
      "source": [
        "# Baseline (Mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_35JxWrCFHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09cff56-a14b-44bb-e2c8-908c8794a5a9"
      },
      "source": [
        "class Baseline(Model):\n",
        "    \"\"\"\n",
        "    Baseline (mean) pipieline.\n",
        "    \"\"\"\n",
        "    def __init__(self, params):\n",
        "        \"\"\"\n",
        "        Init pipeline with datasets, model parameters and performance measurements. \n",
        "        \"\"\"\n",
        "        Model.__init__(self, params)\n",
        "        self.model_name = \"decision_trees\"\n",
        "\n",
        "        self.classes = ['A','B','C','D','E','F','G']\n",
        "        self.y_test_class = None\n",
        "        self.y_pred = None # Consommation energie\n",
        "        self.y_pred_class = None # Classe consommation energie\n",
        "\n",
        "        self.confusion_matrix = None\n",
        "        self.classification_metrics = None \n",
        "\n",
        "        self.run() \n",
        "\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        Fitting mean.\n",
        "        \"\"\"\n",
        "        self.logger.info('Computing mean...')\n",
        "        self.model = DummyRegressor(strategy=\"mean\")\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "        \n",
        "\n",
        "    def model_evaluation(self):\n",
        "        \"\"\"\n",
        "        Evaluate model using classification metrics by converting energy consumption to energy classes.\n",
        "        \"\"\"\n",
        "        self.logger.info('Evaluating mdoel...')\n",
        "        c = self.y_test.copy() \n",
        "        conditions = [(c >= 0) & (c <= 50), (c > 50) & (c <= 90), (c> 90) & (c <= 150),(c > 150) & (c <= 230), (c > 230) & (c <= 330), (c > 330) & (c <450), (c >= 450)]\n",
        "        self.y_test_class = np.select(conditions,self.classes)\n",
        "\n",
        "        c = self.y_pred.copy()\n",
        "        conditions = [(c >= 0) & (c <= 50), (c > 50) & (c <= 90), (c> 90) & (c <= 150),(c > 150) & (c <= 230), (c > 230) & (c <= 330), (c > 330) & (c <450), (c >= 450)]\n",
        "        self.y_pred_class = np.select(conditions,self.classes)\n",
        "\n",
        "        # Compute classification report and confusion matrix\n",
        "        self.classification_metrics = metrics.classification_report(self.y_test_class, self.y_pred_class)\n",
        "        self.confusion_matrix = metrics.confusion_matrix(self.y_test_class, self.y_pred_class)\n",
        "        self.logger.info('Model evaluated!!!')\n",
        "      \n",
        "\n",
        "    def log_confusion_metrics(self):\n",
        "        \"\"\"\n",
        "        Log classification metrics in MLflow tracking experiment.\n",
        "        \"\"\"\n",
        "        self.logger.info('Logging confusion metrics...')\n",
        "        classification_array = self.classification_metrics.split()\n",
        "\n",
        "        i = 5\n",
        "        for classe in self.classes:\n",
        "            precision = float(classification_array[i])\n",
        "            mlflow.log_metric(f\"precision_{classe}\", precision)\n",
        "\n",
        "            recall = float(classification_array[i+1])\n",
        "            mlflow.log_metric(f\"recall_{classe}\", recall)\n",
        "\n",
        "            f1_score = float(classification_array[i+2])\n",
        "            mlflow.log_metric(f\"f1-score_{classe}\", f1_score)\n",
        "\n",
        "            support = float(classification_array[i+3])\n",
        "            mlflow.log_metric(f\"support_{classe}\", support)\n",
        "\n",
        "            i = i+5\n",
        "\n",
        "        accuracy = float(classification_array[i])\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        self.logger.info('Confusion metrics logged!!!')\n",
        "\n",
        "      \n",
        "    def save_plot(self): \n",
        "        \"\"\"\n",
        "        Track confusion matrix plot.\n",
        "        \"\"\"\n",
        "        self.logger.info('Saving plot...')\n",
        "        fig, axes = plt.subplots(figsize=(10,10))\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=self.confusion_matrix, display_labels=self.classes)\n",
        "        disp = disp.plot(ax=axes)\n",
        "        plt.savefig(f\"{self.params.img_path}/confusion_matrix_{self.model_name}.png\")\n",
        "        # Log plot\n",
        "        mlflow.log_artifact(f\"{self.params.img_path}/confusion_matrix_{self.model_name}.png\")\n",
        "\n",
        "        self.logger.info('Plot saved!!!')\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run class methods in order.\n",
        "        \"\"\"\n",
        "        self.logger.info('Running Pipeline...')\n",
        "        self.load_dataset()\n",
        "        self.preprocessing()\n",
        "        self.train_test_split()\n",
        "        self.train_model()\n",
        "        self.predict_target()\n",
        "        self.model_evaluation()\n",
        "        self.log_confusion_metrics()\n",
        "        self.save_plot()\n",
        "\n",
        "        self.logger.info('Done!!!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 116 ms (started: 2021-06-09 08:01:34 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbb7xNnkFLTP"
      },
      "source": [
        "# Init MLflow client\n",
        "mlflow.set_experiment('DPE-Baseline mean')\n",
        "\n",
        "# Start MLflow experiment\n",
        "with mlflow.start_run(run_name='Baseline Mean') as run:\n",
        "    model = Baseline(params=DEFAULT_PARAMETERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59EsZKHmbGgF"
      },
      "source": [
        "# Decision Tree Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRn8xBCJ9wqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ddeb2d-c62f-48cb-bc27-2f2dabbd28cf"
      },
      "source": [
        "class DecisionTree(Model):\n",
        "    \"\"\"\n",
        "    Class to train and tune decison tree regressor model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params):\n",
        "        \"\"\"\n",
        "        Init class with model hyperparameters.\n",
        "        \"\"\"\n",
        "        Model.__init__(self, params)\n",
        "        self.model_name = \"decision_trees\"\n",
        "\n",
        "        self.best_max_depth = None\n",
        "        self.best_min_samples_split = None\n",
        "        self.min_samples_leaf = None\n",
        "        self.min_weight_fraction_leaf = None\n",
        "        self.max_features = None\n",
        "        self.max_leaf_nodes = None\n",
        "        self.best_grid = None\n",
        "        self.best_splitter = None\n",
        "\n",
        "        self.run()\n",
        "\n",
        "\n",
        "    def preprocessing(self):\n",
        "        \"\"\"\n",
        "        Preprocessing dataset, includes encoding categorical features using a frequency encoder,\n",
        "        dropping useless features and selecting the target.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting Decision tree preprocessing...')\n",
        "        encoding = self.dataset.groupby('code_departement').size()\n",
        "        encoding = encoding/len(self.dataset)\n",
        "        self.dataset['code_departement'] = self.dataset.code_departement.map(encoding)\n",
        "\n",
        "        super().preprocessing()\n",
        "\n",
        "    \n",
        "    def parameter_tuning(self):\n",
        "        \"\"\"\n",
        "        Hyperparameter tuning using grid search.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting hyperparameter tuning...')\n",
        "        # Grid parameters \n",
        "        grid_search_params = {\n",
        "                'max_depth': [5, 8, 10],\n",
        "                'min_samples_split' : [10, 100],\n",
        "                'min_samples_leaf':[1,2],\n",
        "                'min_weight_fraction_leaf':[0.0, 0.1],\n",
        "                'max_features':[\"auto\",\"log2\",\"sqrt\",None],\n",
        "                'max_leaf_nodes':[None,10], \n",
        "                'criterion': ['mse'], \n",
        "                'splitter':[\"best\"],\n",
        "                }\n",
        "\n",
        "        # Grid search\n",
        "        tree = DecisionTreeRegressor()\n",
        "        grid = GridSearchCV(tree, grid_search_params, cv=self.params.k_folds)\n",
        "        grid.fit(self.X_train, self.y_train)\n",
        "\n",
        "        # Assign the best parameters\n",
        "        self.best_max_depth = grid.best_params_['max_depth']\n",
        "        self.best_min_samples_split = grid.best_params_['min_samples_split']\n",
        "        self.best_max_leaf_nodes = grid.best_params_['max_leaf_nodes']\n",
        "        self.best_max_features = grid.best_params_['max_features']\n",
        "        self.best_min_weight_fraction_leaf = grid.best_params_['min_weight_fraction_leaf']\n",
        "        self.best_min_samples_leaf = grid.best_params_['min_samples_leaf']\n",
        "        self.best_criterion = grid.best_params_['criterion'] \n",
        "        self.best_splitter = grid.best_params_['splitter']\n",
        "            \n",
        "        # Log the best parameters to Mlflow\n",
        "        self.logger.info('Logging best parameters to MLFlow...')\n",
        "        mlflow.log_param(f'best_max_depth', self.best_max_depth) \n",
        "        mlflow.log_param(f'best_min_samples_split', self.best_min_samples_split)\n",
        "        mlflow.log_param(f'best_max_leaf_nodes', self.best_max_leaf_nodes)\n",
        "        mlflow.log_param(f'best_max_features', self.best_max_features)\n",
        "        mlflow.log_param(f'best_min_weight_fraction_leaf', self.best_min_weight_fraction_leaf)\n",
        "        mlflow.log_param(f'best_min_samples_leaf', self.best_min_samples_leaf)\n",
        "        mlflow.log_param(f'best_criterion', self.best_criterion)\n",
        "        mlflow.log_param(f'best_splitter', self.best_splitter)\n",
        "\n",
        "        self.logger.info('Hyperparameter tuning finished!!!')\n",
        "\n",
        "        \n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        Train model with best hyper-parameters from the grid search.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting training...')\n",
        "        self.model = DecisionTreeRegressor(max_depth=self.best_max_depth, min_samples_split=self.best_min_samples_split,\n",
        "                                        splitter=self.best_splitter, criterion=self.best_criterion)\n",
        "        # Fit model\n",
        "        self.logger.info('Fitting final model...')\n",
        "        self.model.fit(self.X_train, self.y_train) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 72.4 ms (started: 2021-06-09 08:01:57 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CqAGi5lhB9t"
      },
      "source": [
        "# Init MLflow client\n",
        "mlflow.set_experiment('DPE-Decision-Trees')\n",
        "\n",
        "# Start MLflow experiment\n",
        "with mlflow.start_run(run_name='Decision Tree Regression') as run:\n",
        "    model = DecisionTree(params=DEFAULT_PARAMETERS)\n",
        "    pipeline = Pipeline(model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHM8m_jqxIHt"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHmE5qAj9-4g"
      },
      "source": [
        "* **Light GBM** is a gradient boosting framework that uses tree based learning algorithm.\n",
        "\n",
        "\n",
        "* Light GBM grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise.\n",
        "\n",
        "\n",
        "* We chose LightGBM because of its high speed, because it can handle large datasets and it takes lower memory to run. It also focuses on accuracy of results.\n",
        "\n",
        "\n",
        "* For hyperparameter tuning, we chose a **Bayesian hyperparameter Optimization** approach which builds a probability model of the objective function and uses it to select the most promising hyperparameters to evaluate in the true objective function. Here we use gaussian process-based optimisation.\n",
        "\n",
        "* Let's start by splitting the train set into a train set and a validation set. We don't use the test set in the hyper-parameter optimization to avoid any leak :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc34krQ3ncVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8c12fb-7c7b-49c3-d91c-1c2a876fd7fb"
      },
      "source": [
        "class LightGBM(Model):\n",
        "    \"\"\"\n",
        "    Class to train and tune a lightgbm model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params):\n",
        "\n",
        "        Model.__init__(self, params)\n",
        "        self.model_name = \"LightGBM\"\n",
        "\n",
        "        self.cat_features = None\n",
        "        self.best_metric = None\n",
        "        self.best_n_estimators = None\n",
        "        self.num_leaves = None\n",
        "        self.learning_rate = None\n",
        "        self.boosting_type = None\n",
        "        self.best_max_depth = None\n",
        "        \n",
        "        self.run()\n",
        "\n",
        "\n",
        "    def load_dataset(self):\n",
        "        \"\"\"\n",
        "        Load dataset into a pandas dataframe.\n",
        "        \"\"\"\n",
        "        super().load_dataset()\n",
        "\n",
        "\n",
        "    def preprocessing(self):\n",
        "        \"\"\"\n",
        "        Preprocessing dataset, includes casting categorical features,\n",
        "        dropping useless features and selecting the target.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting LightGBM preprocessing...')\n",
        "        self.dataset['code_departement'] = self.dataset['code_departement'].astype('category')\n",
        "        self.dataset['tr002_type_batiment_id'] = self.dataset['tr002_type_batiment_id'].astype('category')\n",
        "        \n",
        "        super().preprocessing()\n",
        "\n",
        "\n",
        "    def train_test_split(self):\n",
        "        \"\"\"\n",
        "        Split data into train and test sets.\n",
        "        \"\"\"\n",
        "        super().train_test_split()\n",
        "\n",
        "    \n",
        "    def parameter_tuning(self):\n",
        "        \"\"\"\n",
        "        Hyperparameter tuning using grid search.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting hyperparameter tuning...')\n",
        "        # Assign categorical features\n",
        "        self.cat_features = ['code_departement', 'tr002_type_batiment_id']\n",
        "\n",
        "        # Parameters \n",
        "        grid_search_params = {\n",
        "                'task': ['train'],\n",
        "                'boosting_type': ['gbdt'],#, 'rf'\n",
        "                'objective': ['regression'],\n",
        "                'metric': ['l2'],#auc\n",
        "                'learning_rate': [0.005], #0.01\n",
        "                'feature_fraction': [0.9],\n",
        "                'bagging_fraction': [0.7],\n",
        "                'bagging_freq': [10],\n",
        "                'verbose': [0],\n",
        "                'max_depth': [8, 10], #10, 12, 25\n",
        "                'num_leaves': [128], #128, 250 \n",
        "                'max_bin': [512],\n",
        "                #\"num_iterations\": [100000],\n",
        "                'n_estimators': [500], # 600\n",
        "                'is_training_metric' : ['True']\n",
        "                }\n",
        "\n",
        "        # Grid search\n",
        "        gbm = lgb.LGBMRegressor()\n",
        "        grid = GridSearchCV(gbm, grid_search_params, cv=self.params.k_folds)\n",
        "        grid.fit(self.X_train, self.y_train, categorical_feature=self.cat_features)\n",
        "\n",
        "        # Assign the best parameters\n",
        "        self.best_metric = grid.best_params_['metric']\n",
        "        self.best_boosting_type = grid.best_params_['boosting_type']\n",
        "        self.best_num_leaves = grid.best_params_['num_leaves']\n",
        "        self.best_learning_rate = grid.best_params_['learning_rate']\n",
        "        self.best_n_estimators = grid.best_params_['n_estimators']\n",
        "        self.best_max_depth = grid.best_params_['max_depth']\n",
        "\n",
        "        # Log the best parameters    \n",
        "        mlflow.log_param(f'best_metric', self.best_metric)\n",
        "        mlflow.log_param(f'best_boosting_type', self.best_boosting_type)\n",
        "        mlflow.log_param(f'best_num_leaves', self.best_num_leaves)\n",
        "        mlflow.log_param(f'best_learning_rate', self.best_learning_rate)\n",
        "        mlflow.log_param(f'best_n_estimators', self.best_n_estimators)\n",
        "        mlflow.log_param(f'best_max_depth', self.best_max_depth)\n",
        "\n",
        "        self.logger.info('Hyperparameter tuning finished!!!')\n",
        "\n",
        "        \n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        Train model with best hyper-parameters from the grid search.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting training...')\n",
        "        self.model = lgb.LGBMRegressor(metric=self.best_metric, n_estimators=self.best_n_estimators, num_leaves=self.num_leaves,\n",
        "                                    boosting_type=self.boosting_type, learning_rate=self.learning_rate)\n",
        "        # Fit model\n",
        "        self.logger.info('Fitting final model...')\n",
        "        self.model.fit(self.X_train, self.y_train, categorical_feature=self.cat_features) \n",
        "        "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 88.8 ms (started: 2021-06-09 08:22:29 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lTsa0FjuLIz"
      },
      "source": [
        "# Init MLflow client\n",
        "mlflow.set_experiment('DPE-LightGBM')\n",
        "\n",
        "# Start MLflow experiment\n",
        "with mlflow.start_run(run_name='LightGBM') as run:\n",
        "    model = LightGBM(params=DEFAULT_PARAMETERS)\n",
        "    pipeline = Pipeline(model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjkwunebzwaH"
      },
      "source": [
        "# Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HlMAIzlub0V",
        "outputId": "0e057f95-f673-4ddd-e681-918d0646e24e"
      },
      "source": [
        "class CatBoost(Model):\n",
        "    \"\"\"\n",
        "    Class to train and tune a CatBoost model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params):\n",
        "\n",
        "        Model.__init__(self, params)\n",
        "        self.model_name = \"CatBoost\"\n",
        "\n",
        "        self.best_iterations = None\n",
        "        self.best_depth = None\n",
        "        self.learning_rate = None\n",
        "        self.num_leaves = None\n",
        "        self.boosting_type = None\n",
        "        self.best_max_depth = None\n",
        "\n",
        "        self.run()\n",
        "\n",
        "\n",
        "    def load_dataset(self):\n",
        "        \"\"\"\n",
        "        Load dataset into a pandas dataframe.\n",
        "        \"\"\"\n",
        "        super().load_dataset()\n",
        "\n",
        "\n",
        "    def preprocessing(self):\n",
        "        \"\"\"\n",
        "        Preprocessing dataset, includes \n",
        "        dropping useless features and selecting the target.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting CatBoost preprocessing...')\n",
        "        super().preprocessing()\n",
        "\n",
        "\n",
        "    def train_test_split(self):\n",
        "        \"\"\"\n",
        "        Split data into train and test sets.\n",
        "        \"\"\"\n",
        "        super().train_test_split()\n",
        "\n",
        "    \n",
        "    def parameter_tuning(self):\n",
        "        \"\"\"\n",
        "        Hyperparameter tuning using grid search.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting hyperparameter tuning...')\n",
        "        # Assign categorical features\n",
        "        #index_1 = self.X_train.columns.get_loc('code_departement')\n",
        "        #index_2 = self.X_train.columns.get_loc('tr002_type_batiment_id')\n",
        "        self.cat_features = ['tr002_type_batiment_id', 'code_departement']\n",
        "\n",
        "        # Parameters \n",
        "        grid_search_params = {\n",
        "                'iterations': [100, 200],#500\n",
        "                'learning_rate': [0.005, 0.01],#, 0.01, 1\n",
        "                'depth': [10, 12] # 10, 12, 25\n",
        "                }\n",
        "  \n",
        "        # Grid search  \n",
        "        cat = cgb.CatBoostRegressor()#silent = True\n",
        "        grid = GridSearchCV(cat, grid_search_params, cv=self.params.k_folds)\n",
        "        grid.fit(self.X_train, self.y_train, cat_features=self.cat_features)\n",
        "\n",
        "        # Assign the best parameters\n",
        "        self.best_iterations = grid.best_params_['iterations']\n",
        "        self.best_learning_rate = grid.best_params_['learning_rate']\n",
        "        self.best_depth = grid.best_params_['depth']\n",
        "        #self.best_num_leaves = grid.best_params_['num_leaves']\n",
        "        #self.best_n_estimators = grid.best_params_['n_estimators']\n",
        "        #self.best_max_depth = grid.best_params_['max_depth']\n",
        "\n",
        "        # Log the best parameters   \n",
        "        mlflow.log_param(f'best_iterations', self.best_iterations)\n",
        "        mlflow.log_param(f'best_learning_rate', self.best_learning_rate)\n",
        "        mlflow.log_param(f'best_depth', self.best_depth)\n",
        "        #mlflow.log_param(f'best_learning_rate', self.best_learning_rate)\n",
        "        #mlflow.log_param(f'best_n_estimators', self.best_n_estimators)\n",
        "        #mlflow.log_param(f'best_max_depth', self.best_max_depth)\n",
        "\n",
        "        self.logger.info('Hyperparameter tuning finished!!!')\n",
        "        \n",
        "        \n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        Train model with best hyper-parameters from the grid search.\n",
        "        \"\"\"\n",
        "        self.logger.info('Starting training...')\n",
        "        self.model = cgb.CatBoostRegressor(depth=self.best_depth, iterations=self.best_iterations, learning_rate=self.learning_rate, silent=True)\n",
        "        # Fit model\n",
        "        self.logger.info('Fitting final model...')\n",
        "        self.model.fit(self.X_train, self.y_train, cat_features=self.cat_features) \n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 59.2 ms (started: 2021-06-09 08:49:01 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfjbXznZCZi0"
      },
      "source": [
        "# Init MLflow client\n",
        "mlflow.set_experiment('DPE-CatBoost')\n",
        "\n",
        "# Start MLflow experiment\n",
        "with mlflow.start_run(run_name='Catboost') as run:\n",
        "    model = CatBoost(params=DEFAULT_PARAMETERS)\n",
        "    pipeline = Pipeline(model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca0JlKmVG47V"
      },
      "source": [
        "# MLflow API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwMk-9brisVa"
      },
      "source": [
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"1sCdZL0vOhPokZP6r1uZFcIG2B5_2AGxAFTUesCxw3MDWPEdw\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_C7PUyjRvd"
      },
      "source": [
        "!mlflow ui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkdC4ka35Fqu"
      },
      "source": [
        "# Save mlruns to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjawChW8Sv9v",
        "outputId": "87e3a487-5644-4a9a-bf42-e7eb031fffdd"
      },
      "source": [
        "!zip -r /content/mlruns.zip  /content/mlruns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: name not matched: /content/mlruns\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/mlruns.zip . -i /content/mlruns)\n",
            "time: 214 ms (started: 2021-06-07 14:08:08 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcOsj7VP5Pk1"
      },
      "source": [
        "shutil.move(\"/content/mlruns\", \"/content/drive/MyDrive/MVP/DPE/mlflow\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}